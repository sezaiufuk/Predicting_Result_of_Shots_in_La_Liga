{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem\n",
    "Our problem is a classification problem, our target is whether a shot is goal or not.\n",
    "\n",
    "# Where Can We Use This Model In Real World ?\n",
    "\n",
    "We can use this model to analyze player performances, understand player habits on the field, determining which players to change in game or find out in advance whether a new player will be compatible with the team or not during transfer seasons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects import pandas2ri\n",
    "import rpy2.robjects.packages as rpackages\n",
    "from rpy2.robjects.conversion import localconverter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from numpy import ravel\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<rpy2.rinterface_lib.sexp.NULLType object at 0x13929ff90> [0]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils = rpackages.importr('utils')\n",
    "utils.chooseCRANmirror(ind=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Dataset Over R from Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Data last updated 2024-05-30 18:34:46.012307882309 UTC\n"
     ]
    }
   ],
   "source": [
    "pandas2ri.activate()\n",
    "ro.r('''\n",
    "        library(\"worldfootballR\")\n",
    "        laliga <- load_understat_league_shots(league = \"La liga\")\n",
    "     ''')\n",
    "laliga = pandas2ri.rpy2py(ro.r['laliga'])\n",
    "laliga.drop('league', axis=1, inplace=True)\n",
    "data=laliga[(laliga['date'] > '2020-06-10') & (laliga['date'] < '2024-06-10')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use La Liga dataset between 2020-06-10 and 2024-06-10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Manipulations and Fixes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a problem about NaN values and duplicate features, we are going to fix these problems by manipulating the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def fixDataNaN(df):\n",
    "    with localconverter(ro.default_converter + pandas2ri.converter):\n",
    "        df = ro.conversion.py2rpy(df)\n",
    "pairs = [['x','X'],['y','Y'],['x_g','xG'],['h_a','home_away'],['shot_type','shotType'],['last_action','lastAction']]\n",
    "\n",
    "def camel_case_columns(df):\n",
    "    def camel_case(column_name):\n",
    "        parts = column_name.split('_')\n",
    "        return str(parts[0] + ''.join(x.title() for x in parts[1:]))\n",
    "    \n",
    "    new_columns = []\n",
    "    for column in df.columns:\n",
    "        if '_' in column:\n",
    "            new_columns.append(camel_case(column))\n",
    "        else:\n",
    "            new_columns.append(str(column))\n",
    "    \n",
    "    df.columns = new_columns\n",
    "    return df\n",
    "\n",
    "def fixMergeColumns(dataList, pairs):\n",
    "    for targetData in dataList:\n",
    "        for pair in pairs:\n",
    "            if pair[0] in targetData.columns and pair[1] in targetData.columns:\n",
    "                targetData['{}'.format(pair[1])].fillna(targetData['{}'.format(pair[0])], inplace=True)\n",
    "                targetData.drop(columns=['{}'.format(pair[0])], inplace=True)\n",
    "        targetData = camel_case_columns(targetData)\n",
    "        fixDataNaN(targetData)\n",
    "\n",
    "fixMergeColumns([data], pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to train our model to predict whether the position ends up to a goal or not so we need to convert our goal and not goal situations to binary tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement_dict = {\n",
    "    'Goal': 1,\n",
    "    'BlockedShot': 0,\n",
    "    'MissedShots': 0,\n",
    "    'SavedShot': 0,\n",
    "    'ShotOnPost': 0,\n",
    "    'OwnGoal': 0\n",
    "}\n",
    "\n",
    "data['result'] = pd.DataFrame(data['result'].map(replacement_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We changed string values to numerical values for the training to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('result', axis=1)\n",
    "base_data = data\n",
    "Y = data['result']\n",
    "X = pd.get_dummies(X)\n",
    "data = pd.concat([pd.DataFrame(Y),pd.DataFrame(X)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the data into training and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_shuffled = data.sample(frac=1, random_state=42)\n",
    "quarter_length = len(data_shuffled) // 4\n",
    "df_half_val = data_shuffled.iloc[:quarter_length]\n",
    "df_half_train = data_shuffled.iloc[quarter_length:]\n",
    "\n",
    "data = df_half_train\n",
    "validation_data = df_half_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the validation data into X and Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_validation = validation_data['result']\n",
    "x_validation = validation_data.drop('result', axis=1)\n",
    "\n",
    "X = pd.DataFrame(data.drop('result', axis=1))\n",
    "Y = pd.DataFrame(data['result'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>minute</th>\n",
       "      <th>result</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>xG</th>\n",
       "      <th>player</th>\n",
       "      <th>playerId</th>\n",
       "      <th>situation</th>\n",
       "      <th>season</th>\n",
       "      <th>shotType</th>\n",
       "      <th>matchId</th>\n",
       "      <th>homeTeam</th>\n",
       "      <th>awayTeam</th>\n",
       "      <th>homeGoals</th>\n",
       "      <th>awayGoals</th>\n",
       "      <th>date</th>\n",
       "      <th>playerAssisted</th>\n",
       "      <th>lastAction</th>\n",
       "      <th>homeAway</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51957</th>\n",
       "      <td>364045.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.063956</td>\n",
       "      <td>Munir</td>\n",
       "      <td>2106.0</td>\n",
       "      <td>OpenPlay</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>LeftFoot</td>\n",
       "      <td>12301.0</td>\n",
       "      <td>Sevilla</td>\n",
       "      <td>Real Betis</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-06-11 20:00:00</td>\n",
       "      <td>Sergio Reguilón</td>\n",
       "      <td>Pass</td>\n",
       "      <td>h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51958</th>\n",
       "      <td>364046.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.044106</td>\n",
       "      <td>Lucas Ocampos</td>\n",
       "      <td>1109.0</td>\n",
       "      <td>OpenPlay</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>RightFoot</td>\n",
       "      <td>12301.0</td>\n",
       "      <td>Sevilla</td>\n",
       "      <td>Real Betis</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-06-11 20:00:00</td>\n",
       "      <td>Jesús Navas</td>\n",
       "      <td>TakeOn</td>\n",
       "      <td>h</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  minute  result      X      Y        xG         player  \\\n",
       "51957  364045.0     5.0       0  0.862  0.655  0.063956          Munir   \n",
       "51958  364046.0     9.0       0  0.920  0.265  0.044106  Lucas Ocampos   \n",
       "\n",
       "       playerId situation  season   shotType  matchId homeTeam    awayTeam  \\\n",
       "51957    2106.0  OpenPlay  2019.0   LeftFoot  12301.0  Sevilla  Real Betis   \n",
       "51958    1109.0  OpenPlay  2019.0  RightFoot  12301.0  Sevilla  Real Betis   \n",
       "\n",
       "       homeGoals  awayGoals                 date   playerAssisted lastAction  \\\n",
       "51957        2.0        0.0  2020-06-11 20:00:00  Sergio Reguilón       Pass   \n",
       "51958        2.0        0.0  2020-06-11 20:00:00      Jesús Navas     TakeOn   \n",
       "\n",
       "      homeAway  \n",
       "51957        h  \n",
       "51958        h  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Variable\n",
    "\n",
    "Our target variable is \"result\", this feature represents whether a shot is a goal or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features\n",
    "\n",
    "Our features are going to help our model to learn and predict the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'minute', 'result', 'X', 'Y', 'xG', 'player', 'playerId', 'situation', 'season', 'shotType', 'matchId', 'homeTeam', 'awayTeam', 'homeGoals', 'awayGoals', 'date', 'playerAssisted', 'lastAction', 'homeAway']\n"
     ]
    }
   ],
   "source": [
    "print(base_data.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imbalancedness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data has imbalancedness problem which might cause our model to learn features of majority target variables better than the minority target variables, it might cause inaccurate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result\n",
      "0    25655\n",
      "1     2980\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['result'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are tried to use SMOTE method for oversampling to fix the gap between minority and majority target variables. This method uses clustering methods to create new observations based on original ones.\n",
    "\n",
    "But SMOTE did not work efficient on our data, it caused overfitting problem because synthetic generated minority observations did not represent our minority class well.\n",
    "\n",
    "We are going to disable block below since we do not use it as our primary method and for the sake of process time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sm = SMOTE(random_state=42,n_jobs=-1)\n",
    "# x_res, y_res = sm.fit_resample(X, Y)\n",
    "\n",
    "# data_res = pd.concat([pd.DataFrame(y_res), pd.DataFrame(x_res)], axis=1)\n",
    "# print(y_res.value_counts())\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "\n",
    "# x_res = scaler.fit_transform(x_res)\n",
    "\n",
    "# X_validation = scaler.fit_transform(x_validation)\n",
    "\n",
    "# Y_validation = validation_data['result']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used undersampling method to solve imbalancedness problem by decreasing majority count with sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result\n",
      "0         2980\n",
      "1         2980\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_rus, Y_rus = rus.fit_resample(X, Y)\n",
    "x_rus = pd.DataFrame(X_rus)\n",
    "y_rus = pd.DataFrame(Y_rus)\n",
    "\n",
    "print(y_rus.value_counts())\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "x_rus = scaler.fit_transform(x_rus)\n",
    "\n",
    "X_validation = scaler.fit_transform(x_validation)\n",
    "\n",
    "Y_validation = validation_data['result']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison Over Sampling Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used both SMOTE and Undersampling methods, we figured out that the SMOTE method is not working effectively on our data and causing overfitting problem, so we choose to use Undersampling method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_rus, x_test_rus, y_train_rus, y_test_rus = train_test_split(x_rus, y_rus, test_size=0.25, random_state=42)\n",
    "# x_train_res, x_test_res, y_train_res, y_test_res = train_test_split(x_res, y_res, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "# model_res = GradientBoostingClassifier(random_state=42)\n",
    "# model_res.fit(x_train_res, y_train_res)\n",
    "\n",
    "# y_pred_res = model_res.predict(x_test_res)\n",
    "\n",
    "# y_train_res = y_train_res.astype(y_pred_res.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5-Fold Cross Validation score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(cross_val_score(model_res, x_train_res, y_train_res, cv=5, scoring='balanced_accuracy').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "model_rus = GradientBoostingClassifier(random_state=42)\n",
    "model_rus.fit(x_train_rus, y_train_rus)\n",
    "\n",
    "y_pred_rus = model_rus.predict(x_test_rus)\n",
    "\n",
    "y_train_rus = y_train_rus.astype(y_pred_rus.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5-Fold Cross Validation score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7857051326801918\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(model_rus, x_train_rus, y_train_rus, cv=5, scoring='balanced_accuracy').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that our model is overfitting because of the synthetic generated observations of minority class are not representing our minority class well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_validation_pred_res = model_res.predict(X_validation)\n",
    "\n",
    "# print(confusion_matrix(Y_validation, y_validation_pred_res))\n",
    "\n",
    "# print(balanced_accuracy_score(Y_validation, y_validation_pred_res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with Undersampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Undersampling method works well, our balanced accuracy score on validation data is good, there is no sign of overfitting because our test and validation predictions' balanced accuracy scores are close to each other also we fixed imbalancedness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7007 1519]\n",
      " [ 247  771]]\n",
      "0.7896032337465845\n"
     ]
    }
   ],
   "source": [
    "y_validation_pred_rus = model_rus.predict(X_validation)\n",
    "\n",
    "print(confusion_matrix(Y_validation, y_validation_pred_rus))\n",
    "\n",
    "print(balanced_accuracy_score(Y_validation, y_validation_pred_rus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Model and Hyperparameter Tuning with AutoML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the H2O AutoML to find best hyperparameters and model to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: openjdk version \"11.0.11\" 2021-04-20; OpenJDK Runtime Environment AdoptOpenJDK-11.0.11+9 (build 11.0.11+9); OpenJDK 64-Bit Server VM AdoptOpenJDK-11.0.11+9 (build 11.0.11+9, mixed mode)\n",
      "  Starting server from /Users/sezaiufukoral/anaconda3/lib/python3.11/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /var/folders/v_/rk6mkc692tsd60fr3klt7tfm0000gn/T/tmpttwo7c7t\n",
      "  JVM stdout: /var/folders/v_/rk6mkc692tsd60fr3klt7tfm0000gn/T/tmpttwo7c7t/h2o_sezaiufukoral_started_from_python.out\n",
      "  JVM stderr: /var/folders/v_/rk6mkc692tsd60fr3klt7tfm0000gn/T/tmpttwo7c7t/h2o_sezaiufukoral_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-1.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-1 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-1 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-1 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table th,\n",
       "#h2o-table-1 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>02 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Europe/Istanbul</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.46.0.2</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>27 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_sezaiufukoral_eq1iiq</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>2 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.11.9 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  ------------------------------------\n",
       "H2O_cluster_uptime:         02 secs\n",
       "H2O_cluster_timezone:       Europe/Istanbul\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.46.0.2\n",
       "H2O_cluster_version_age:    27 days\n",
       "H2O_cluster_name:           H2O_from_python_sezaiufukoral_eq1iiq\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    2 Gb\n",
       "H2O_cluster_total_cores:    8\n",
       "H2O_cluster_allowed_cores:  8\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://127.0.0.1:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.11.9 final\n",
       "--------------------------  ------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.DataFrame(x_train_rus)\n",
    "new_data['result'] = y_train_rus.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "hf = h2o.H2OFrame(new_data)\n",
    "\n",
    "train_hf, test_hf = hf.split_frame(ratios=[0.75], seed = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML progress: |███████████████████████████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style='margin: 1em 0 1em 0;'>Model Details\n",
       "=============\n",
       "H2OStackedEnsembleEstimator : Stacked Ensemble\n",
       "Model Key: StackedEnsemble_BestOfFamily_1_AutoML_1_20240610_60212\n",
       "</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-2.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-2 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-2 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-2 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-2 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-2 .h2o-table th,\n",
       "#h2o-table-2 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-2 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-2\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Model Summary for Stacked Ensemble: </caption>\n",
       "    <thead><tr><th>key</th>\n",
       "<th>value</th></tr></thead>\n",
       "    <tbody><tr><td>Stacking strategy</td>\n",
       "<td>blending</td></tr>\n",
       "<tr><td>Number of base models (used / total)</td>\n",
       "<td>4/5</td></tr>\n",
       "<tr><td># GBM base models (used / total)</td>\n",
       "<td>1/1</td></tr>\n",
       "<tr><td># XGBoost base models (used / total)</td>\n",
       "<td>1/1</td></tr>\n",
       "<tr><td># DRF base models (used / total)</td>\n",
       "<td>2/2</td></tr>\n",
       "<tr><td># GLM base models (used / total)</td>\n",
       "<td>0/1</td></tr>\n",
       "<tr><td>Metalearner algorithm</td>\n",
       "<td>GLM</td></tr>\n",
       "<tr><td>Metalearner fold assignment scheme</td>\n",
       "<td>AUTO</td></tr>\n",
       "<tr><td>Metalearner nfolds</td>\n",
       "<td>0</td></tr>\n",
       "<tr><td>Metalearner fold_column</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>Custom metalearner hyperparameters</td>\n",
       "<td>None</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsRegressionGLM: stackedensemble\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.054983956544412856\n",
       "RMSE: 0.23448658073419223\n",
       "MAE: 0.18927251396444109\n",
       "RMSLE: 0.16400018081581103\n",
       "Mean Residual Deviance: 0.054983956544412856\n",
       "R^2: 0.7800523742344401\n",
       "Null degrees of freedom: 2320\n",
       "Residual degrees of freedom: 2316\n",
       "Null deviance: 582.6524951143185\n",
       "Residual deviance: 127.61776313958224\n",
       "AIC: -133.84414104697873</pre></div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsRegressionGLM: stackedensemble\n",
       "** Reported on validation data. **\n",
       "\n",
       "MSE: 0.1413395879019311\n",
       "RMSE: 0.37595157653869615\n",
       "MAE: 0.30481175990678305\n",
       "RMSLE: 0.26092892971452203\n",
       "Mean Residual Deviance: 0.1413395879019311\n",
       "R^2: 0.43443133439873816\n",
       "Null degrees of freedom: 362\n",
       "Residual degrees of freedom: 358\n",
       "Null deviance: 91.25042024462027\n",
       "Residual deviance: 51.30627040840099\n",
       "AIC: 331.90725615369536</pre></div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
      ],
      "text/plain": [
       "Model Details\n",
       "=============\n",
       "H2OStackedEnsembleEstimator : Stacked Ensemble\n",
       "Model Key: StackedEnsemble_BestOfFamily_1_AutoML_1_20240610_60212\n",
       "\n",
       "\n",
       "Model Summary for Stacked Ensemble: \n",
       "key                                   value\n",
       "------------------------------------  --------\n",
       "Stacking strategy                     blending\n",
       "Number of base models (used / total)  4/5\n",
       "# GBM base models (used / total)      1/1\n",
       "# XGBoost base models (used / total)  1/1\n",
       "# DRF base models (used / total)      2/2\n",
       "# GLM base models (used / total)      0/1\n",
       "Metalearner algorithm                 GLM\n",
       "Metalearner fold assignment scheme    AUTO\n",
       "Metalearner nfolds                    0\n",
       "Metalearner fold_column\n",
       "Custom metalearner hyperparameters    None\n",
       "\n",
       "ModelMetricsRegressionGLM: stackedensemble\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.054983956544412856\n",
       "RMSE: 0.23448658073419223\n",
       "MAE: 0.18927251396444109\n",
       "RMSLE: 0.16400018081581103\n",
       "Mean Residual Deviance: 0.054983956544412856\n",
       "R^2: 0.7800523742344401\n",
       "Null degrees of freedom: 2320\n",
       "Residual degrees of freedom: 2316\n",
       "Null deviance: 582.6524951143185\n",
       "Residual deviance: 127.61776313958224\n",
       "AIC: -133.84414104697873\n",
       "\n",
       "ModelMetricsRegressionGLM: stackedensemble\n",
       "** Reported on validation data. **\n",
       "\n",
       "MSE: 0.1413395879019311\n",
       "RMSE: 0.37595157653869615\n",
       "MAE: 0.30481175990678305\n",
       "RMSLE: 0.26092892971452203\n",
       "Mean Residual Deviance: 0.1413395879019311\n",
       "R^2: 0.43443133439873816\n",
       "Null degrees of freedom: 362\n",
       "Residual degrees of freedom: 358\n",
       "Null deviance: 91.25042024462027\n",
       "Residual deviance: 51.30627040840099\n",
       "AIC: 331.90725615369536\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section."
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aml = H2OAutoML(max_models = 12,\n",
    "                balance_classes=True,\n",
    "\t\tseed=1,max_runtime_secs=220,verbosity='none')\n",
    "\n",
    "aml.train(training_frame = train_hf, y='result')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing the Final Model\n",
    "\n",
    "We are going to test our models with a new, unseen data to check balanced accuracy scores and confusion matrices to choose our final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7007 1519]\n",
      " [ 247  771]]\n",
      "0.7896032337465845\n"
     ]
    }
   ],
   "source": [
    "y_validation_pred = model_rus.predict(X_validation)\n",
    "\n",
    "print(confusion_matrix(Y_validation, y_validation_pred))\n",
    "\n",
    "print(balanced_accuracy_score(Y_validation, y_validation_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "stackedensemble prediction progress: |███████████████████████████████████████████| (done) 100%\n",
      "Balanced Accuracy Score:  0.7877924084748051\n",
      "[[7085 1441]\n",
      " [ 260  758]]\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "validation_x_hf = h2o.H2OFrame(pd.DataFrame(X_validation))\n",
    "validation_y_hf = h2o.H2OFrame(pd.DataFrame(Y_validation))\n",
    "\n",
    "validation_y_hf.columns = ['result']\n",
    "\n",
    "preds_validation = aml.leader.predict(validation_x_hf)\n",
    "\n",
    "y_validation_test_se = validation_y_hf['result'].as_data_frame().values.flatten()\n",
    "y_validation_pred_se = preds_validation['predict'].round().as_data_frame().values.flatten()\n",
    "\n",
    "balanced_acc = balanced_accuracy_score(y_validation_test_se, y_validation_pred_se)\n",
    "print(\"Balanced Accuracy Score: \", balanced_acc)\n",
    "\n",
    "print(confusion_matrix(y_validation_test_se, y_validation_pred_se))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the Stacked Ensemble and vanilla Gradient Boosting Machines algorithms' metrics show similar performance to each other. However, given that knowing if a shot results in a goal is the dominant information we want to obtain according to domain knowledge, also for the sake of process time, we choose our model to be vanilla Gradient Boosting Machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'model.pkl'\n",
    "pickle.dump(model_rus, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
